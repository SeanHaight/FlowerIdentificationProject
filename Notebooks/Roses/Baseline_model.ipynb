{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build the baseline model to compare our image recognition models against. We first ensure that we're only dealing with rose observations that have been labeled as flowering or not. We then test the accuracy of four different models. The first model just predicts observations from May, June or July to be in bloom and others to not be in bloom. We then use five fold cross-validation to test the generalization accuracy of three other models listed below: \n",
    "\n",
    "* Logistic Regression\n",
    "* Random Forest Classifier\n",
    "* Gradient Boosting Classifier\n",
    "\n",
    "These three models are fit on the following variables from each observation: \n",
    "\n",
    "* Year\n",
    "* Month\n",
    "* Day \n",
    "* Latitude\n",
    "* Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Get rid of SettingWithCopyWarnings\n",
    "pd.options.mode.chained_assignment = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roseObs = pd.read_csv(\"../../Data/processedData/Roses/roseObs\")\n",
    "labeledRoseObs = roseObs.dropna()\n",
    "\n",
    "#Create column for whether the observation is of a plant that is in bloom or not. \n",
    "labeledRoseObs[\"isFlowering\"] = labeledRoseObs['reproductiveCondition'].isin(['flowering','flowering|fruiting','flowering|fruiting|flower budding','flowering|flower budding']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe try to use log10 in your analysis. We can also compute the correlation. We could compare mean and median of variables as a function of categorical variables.Even better we can make a box and whisker plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78061674, 0.80264317, 0.81674009, 0.79118943, 0.77621145],\n",
       "       [0.76740088, 0.76651982, 0.78414097, 0.77621145, 0.77268722],\n",
       "       [0.86696035, 0.88193833, 0.88105727, 0.86079295, 0.85550661],\n",
       "       [0.86343612, 0.87136564, 0.87312775, 0.85991189, 0.83964758]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=97, shuffle=True)\n",
    "training_vars = [\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]\n",
    "\n",
    "#This will be an array that holds the generalization accuracy of each model on each of the different splits\n",
    "accuracy = np.zeros((4, 5))\n",
    "\n",
    "# Set a counter for what split we're on\n",
    "i = 0\n",
    "\n",
    "#For each split of the data, fit our four models and compute the generalization accuracy\n",
    "for train_index, val_index in kfold.split(labeledRoseObs):\n",
    "    \n",
    "    roses_train = labeledRoseObs.iloc[train_index]\n",
    "    roses_val = labeledRoseObs.iloc[val_index]\n",
    "    \n",
    "    # \"Fit\" and get validation error for the baseline model\n",
    "    baseline_pred = []\n",
    "    for month in roses_val[\"month\"]:\n",
    "        # a better way to do this would be to check which months have a majority of observations in flower\n",
    "        if month in [5,6,7]:\n",
    "            baseline_pred.append(1)\n",
    "        else:\n",
    "            baseline_pred.append(0)\n",
    "    \n",
    "    #Compute the accuracy on the validation set\n",
    "    accuracy[0, i] = 1 - sum(abs(np.array(roses_val[\"isFlowering\"]) - np.array(baseline_pred)))/len(roses_val)\n",
    "    \n",
    "    ## Fit and get the accuracy on the validation set for the remaining models\n",
    "    LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "    LR.fit(roses_train[training_vars], roses_train[\"isFlowering\"])\n",
    "    pred = LR.predict(roses_val[training_vars])\n",
    "    accuracy[1,i] = 1 - sum(abs(np.array(roses_val[\"isFlowering\"]) - np.array(pred)))/len(roses_val)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators= 200, max_depth=400, random_state=97)\n",
    "    RF.fit(roses_train[training_vars], roses_train[\"isFlowering\"])\n",
    "    pred = RF.predict(roses_val[training_vars])\n",
    "    accuracy[2,i] = 1 - sum(abs(np.array(roses_val[\"isFlowering\"]) - np.array(pred)))/len(roses_val)\n",
    "\n",
    "    GB = GradientBoostingClassifier(n_estimators = 400, max_leaf_nodes = 10, max_depth =  None, random_state = 97, min_samples_split = 10)\n",
    "    GB.fit(roses_train[training_vars], roses_train[\"isFlowering\"])\n",
    "    pred = GB.predict(roses_val[training_vars])\n",
    "    accuracy[3,i] = 1 - sum(abs(np.array(roses_val[\"isFlowering\"]) - np.array(pred)))/len(roses_val)\n",
    "\n",
    "    \n",
    "    ## Increasing the counter\n",
    "    i = i + 1\n",
    "\n",
    "#Print out our accuracy table at the end.\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79348018, 0.77339207, 0.8692511 , 0.8614978 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the mean accuracy of each row to determine which model performs best on average\n",
    "np.mean(accuracy,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Random Forest Classifier performs the best so far with a generalization accuracy of almost 87%. This will be the model we want to compare our CV model against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
