{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import pyinaturalist as iNat\n",
    "roseObs = pd.read_csv(\"processedData/roseObs\")\n",
    "labeledRoseObs = roseObs.dropna()\n",
    "labeledRoseObs[\"isFlowering\"] = labeledRoseObs['reproductiveCondition'].isin(['flowering','flowering|fruiting','flowering|fruiting|flower budding','flowering|flower budding']).astype(int)\n",
    "numList = []\n",
    "\n",
    "for link in labeledRoseObs[\"references\"]:\n",
    "    numList.append(int(link.split(\"/\")[-1]))\n",
    "\n",
    "labeledRoseObs[\"observationNumber\"] = numList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe try to use log10 in your analysis. We can also compute the correlation. We could compare mean and median of variables as a function of categorical variables.Even better we can make a box and whisker plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=44, shuffle=True)\n",
    "\n",
    "accuracy = np.zeros((4, 5))\n",
    "## sets a split counter\n",
    "i = 0\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(labeledRoseObs):\n",
    "    ## get the cv training set\n",
    "    roses_tt = labeledRoseObs.iloc[train_index]\n",
    "    \n",
    "    ## get the cv holdout set\n",
    "    roses_ho = labeledRoseObs.iloc[test_index]\n",
    "    \n",
    "    ## \"Fit\" and get ho mse for the baseline model\n",
    "    baseline_pred = []\n",
    "    for month in roses_ho[\"month\"]:\n",
    "        # a better way to do this would be to check which months have a majority of observations in flower\n",
    "        if month in [5,6,7]:\n",
    "            baseline_pred.append(1)\n",
    "        else:\n",
    "            baseline_pred.append(0)\n",
    "    \n",
    "    accuracy[0, i] = 1 - sum(abs(np.array(roses_ho[\"isFlowering\"]) - np.array(baseline_pred)))/len(roses_ho)\n",
    "    \n",
    "    ## Fit and get the mses for the remaining models\n",
    "    LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(roses_tt[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]], roses_tt[\"isFlowering\"])\n",
    "    pred = LR.predict(roses_ho[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]])\n",
    "    accuracy[1,i] = 1 - sum(abs(np.array(roses_ho[\"isFlowering\"]) - np.array(pred)))/len(roses_ho)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators= 200, max_depth=400, random_state=0)\n",
    "    RF.fit(roses_tt[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]], roses_tt[\"isFlowering\"])\n",
    "    pred = RF.predict(roses_ho[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]])\n",
    "    accuracy[2,i] = 1 - sum(abs(np.array(roses_ho[\"isFlowering\"]) - np.array(pred)))/len(roses_ho)\n",
    "\n",
    "    GB = GradientBoostingClassifier(n_estimators = 400, max_leaf_nodes = 10, max_depth =  None, random_state = 2, min_samples_split = 10)\n",
    "    GB.fit(roses_tt[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]], roses_tt[\"isFlowering\"])\n",
    "    pred = GB.predict(roses_ho[[\"year\", \"month\", \"day\", \"decimalLatitude\", \"decimalLongitude\"]])\n",
    "    accuracy[3,i] = 1 - sum(abs(np.array(roses_ho[\"isFlowering\"]) - np.array(pred)))/len(roses_ho)\n",
    "\n",
    "    \n",
    "    ## Increasing the counter\n",
    "    i = i + 1\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy,axis = 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
